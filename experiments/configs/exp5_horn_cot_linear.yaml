name: exp5_horn_cot_linear
temperature: 0
seed: 1234
max_tokens: 2000

input_file: data/problems_dist20_v1.js
output_pattern: experiments/runs/${name}/${provider}_${model}.jsonl

filters:
  horn_only: true
  skip_rows: 1

prompt:
  template: prompts/exp5_horn_cot_linear.j2
  style: horn_if_then

parse:
  type: yes_no

concurrency:
  workers: 4
  rate_limit_per_min: 120
  retry:
    max_attempts: 3
    backoff_seconds: [2, 5, 10]

resume: true
save_prompt: false
save_response: true

targets:
  - provider: openai
    model: gpt-4o-2024-11-20
    temperature: 0
  - provider: anthropic
    model: claude-3-5-sonnet-latest
    temperature: 0

