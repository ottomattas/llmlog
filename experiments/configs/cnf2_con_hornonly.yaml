# Experiment 6: Compact CNF on Horn problems only
# Purpose: Compare compact CNF representation on Horn subset
# Representation: cnf_v2 (compact symbolic)
# Task: contradiction (is the set contradictory?)
# Filter: horn_only=true (520 Horn problems from validation, 2080 from production)

name: cnf2_con_hornonly

# All 12 models (IDENTICAL across all experiments)
targets:
  # Tier 1: Flagship models with high thinking
  - provider: anthropic
    model: claude-sonnet-4-5-20250929
    temperature: 1
    seed: 1234
    max_tokens: 30000
    thinking:
      enabled: true
      budget_tokens: 24576

  - provider: google
    model: gemini-2.5-pro
    temperature: 0
    seed: 1234
    max_tokens: 30000
    thinking:
      enabled: true
      budget_tokens: 24576

  - provider: openai
    model: gpt-5-2025-08-07    # gpt-5-pro-2025-10-06 is expensive
    temperature: 0
    seed: 1234
    max_tokens: 30000
    thinking:
      enabled: true
      effort: high

  # Tier 2: Medium models with medium thinking
  - provider: anthropic
    model: claude-haiku-4-5-20251001  # claude-opus-4-1-20250805 is expensive
    temperature: 1
    seed: 1234
    max_tokens: 10000
    thinking:
      enabled: true
      budget_tokens: 8192

  - provider: google
    model: gemini-2.5-flash
    temperature: 0
    seed: 1234
    max_tokens: 10000
    thinking:
      enabled: true
      budget_tokens: 8192

  - provider: openai
    model: gpt-5-2025-08-07
    temperature: 0
    seed: 1234
    max_tokens: 10000
    thinking:
      enabled: true
      effort: medium

  # Tier 3: Budget models with low thinking
  - provider: anthropic
    model: claude-haiku-4-5-20251001
    temperature: 1              # Anthropic requires temp=1 when thinking enabled
    seed: 1234
    max_tokens: 3000
    thinking:
      enabled: true
      budget_tokens: 1024

  - provider: google
    model: gemini-2.5-flash-lite
    temperature: 0
    seed: 1234
    max_tokens: 3000
    thinking:
      enabled: true
      budget_tokens: 1024

  - provider: openai
    model: gpt-5-mini-2025-08-07
    temperature: 0
    seed: 1234
    max_tokens: 3000
    thinking:
      enabled: true
      effort: low

  # Tier 3: Budget models with NO thinking
  - provider: anthropic
    model: claude-haiku-4-5-20251001
    temperature: 0
    seed: 1234
    max_tokens: 3000
    thinking:
      enabled: false

  - provider: google
    model: gemini-2.5-flash-lite
    temperature: 0
    seed: 1234
    max_tokens: 3000
    thinking:
      enabled: false

  - provider: openai
    model: gpt-5-nano-2025-08-07
    temperature: 0
    seed: 1234
    max_tokens: 3000
    thinking:
      enabled: false

# Input dataset - START WITH VALIDATION
input_file: data/problems_validation_vars4-20_len2-5_percase4_seed42424.js
# After validation success, switch to:
# input_file: data/problems_production_vars1-20_len2-5_percase40_seed42424.js

# Filters
filters:
  horn_only: true         # Only use Horn problems
  skip_rows: 1
  limit_rows: null

# Output paths - includes ${thinking_mode} to distinguish same model with/without thinking
output_pattern: experiments/runs/${name}/${run}/${provider}/${model}/${thinking_mode}/results.jsonl

# Outputs configuration
outputs:
  results:
    enabled: true
  provenance:
    enabled: true
    include_prompt: true
    include_raw_response: true

# Prompt configuration
prompt:
  template: prompts/_template_unified.j2
  style: cnf_v2            # Compact: "p1 or not(p2)."
  variables: {}

# Parser configuration
parse:
  type: contradiction
  yes_tokens: []
  no_tokens: []

# Concurrency
concurrency:
  workers: 12
  lockstep: true
  targets_workers: 3
  rate_limit_per_min: 120
  retry:
    max_attempts: 3
    backoff_seconds: [2, 5, 10]

# Execution
resume: true

