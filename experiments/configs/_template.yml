# Reusable Experiment Template
## How to use
# 1) Copy this file and rename it, or edit in-place (change `name:`).
# 2) Define one or more targets via `targets:`.
# 3) Adjust input/output paths, prompt template, parser, and concurrency.
#
## Sections overview
# - Name
# - Target selection
# - Input data
# - Input filters
# - Output data
# - Output configuration
# - Prompt
# - Parsing
# - Concurrency
# - Execution
# - CLI tips

## Name
# Recommended naming scheme
# Use: exp<N>_<domain>_<task>[_<variant>]
# - <domain>: cnf | horn
# - <task>: contradiction | yesno | cot
# - <variant> (optional): linear | parents | v1 | v2
# Examples
# - exp1_cnf_v1
# - exp3_cnf_cot_linear
# - exp4_cnf_cot_parents
# - exp5_horn_cot_linear
# - exp6_horn_yesno
name: CHANGE_ME_experiment_name

## Target selection
# Thinking tiers for comparison:
# - Flagship: highest thinking effort/budget
# - Medium: moderate thinking effort/budget
# - Budget/Fast: thinking disabled
# Models for each thinking tier:
# - High effort (Flagship): claude-opus-4-1-20250805, gemini-2.5-pro, gpt-5-2025-08-07
# - Medium effort (Medium): claude-sonnet-4-20250514, gemini-2.5-flash, gpt-5-mini-2025-08-07
# - Low/Budget (Fast): claude-3-5-haiku-20241022, gemini-2.5-flash-lite, gpt-5-nano-2025-08-07
# Tokens for each thinking tier:
# - This is informed by the mapping of low/medium/high reasoning effort to tokens in the compatibility documentation: https://ai.google.dev/gemini-api/docs/openai#thinking
# - High effort (Flagship): 24576
# - Medium effort (Medium): 8192
# - Low/Budget (Fast): 1024
# Official documentation on thinking:
# - Anthropic: https://docs.claude.com/en/docs/build-with-claude/extended-thinking
# - Google: https://ai.google.dev/gemini-api/docs/thinking
# - OpenAI: https://platform.openai.com/docs/guides/reasoning/advice-on-prompting#get-started-with-reasoning
# Notes:
# - Anthropic requires temperature=1 when thinking is enabled
# - For Anthropic, max_tokens must be > thinking.budget_tokens
# - For Google, thinking uses thinkingConfig.thinkingBudget (we use unified 'budget_tokens')
# - For OpenAI, reasoning effort can be high/medium; disabled for budget tier
# - For a single-target run, keep ONE item in this list
# - To run multiple models for the same provider, add another target entry
#
# Gemini-specific toggles (client behavior implemented, via unified 'budget_tokens'):
# - budget_tokens: 0 → disables thinking on Flash / Flash Lite (for Pro it is converted to -1, dynamic)
# - budget_tokens: -1 → enables dynamic thinking on Pro / Flash / Flash Lite
# - Positive budgets are clamped per model family (Pro: 128–32768; Flash: 0–24576; Flash Lite: 512–24576)
# OpenAI reasoning (official):
# - Only 'reasoning: { effort: low|medium|high }' is supported
# - Defaults to medium when omitted; no numeric budgets
# - Responses API preferred for reasoning models; Chat Completions supported with reduced features
 
targets:
  - provider: anthropic
    model: claude-opus-4-1-20250805    # Flagship
    temperature: 1                     # Anthropic: must be 1 when thinking enabled
    seed: 1234
    max_tokens: 30000
    thinking:
      enabled: true
      budget_tokens: 24576             # High effort
  - provider: anthropic
    model: claude-sonnet-4-20250514    # Medium
    temperature: 1                     # Anthropic: must be 1 when thinking enabled
    seed: 1234
    max_tokens: 10000
    thinking:
      enabled: true
      budget_tokens: 8192              # Medium effort
  - provider: anthropic
    model: claude-3-5-haiku-20241022   # Budget/Fast
    temperature: 0
    seed: 1234
    max_tokens: 3000
    thinking:
      enabled: false                   # Budget/Fast: reasoning disabled
  - provider: google
    model: gemini-2.5-pro              # Flagship
    temperature: 0
    seed: 1234
    max_tokens: 30000
    thinking:
      enabled: true
      budget_tokens: 24576             # High effort (cannot disable on Pro; 0 → -1 dynamic)
  - provider: google
    model: gemini-2.5-flash            # Medium
    temperature: 0
    seed: 1234
    max_tokens: 10000
    thinking:
      enabled: true
      budget_tokens: 8192              # Medium effort (set 0 to disable; -1 for dynamic)
  - provider: google
    model: gemini-2.5-flash-lite       # Budget/Fast
    temperature: 0
    seed: 1234
    max_tokens: 3000
    thinking:
      enabled: false                   # Budget/Fast: reasoning disabled (you may also set enabled: true with 0 to keep off, or -1 for dynamic)
  - provider: openai
    model: gpt-5-2025-08-07            # Flagship
    temperature: 0
    seed: 1234
    max_tokens: 30000
    thinking:
      enabled: true
      openai_reasoning:
        effort: high                   # High effort (official values: low|medium|high)
  - provider: openai
    model: gpt-5-mini-2025-08-07       # Medium
    temperature: 0
    seed: 1234
    max_tokens: 10000
    thinking:
      enabled: true
      openai_reasoning:
        effort: medium                 # Medium effort (official values)
  - provider: openai
    model: gpt-5-nano-2025-08-07       # Budget/Fast
    temperature: 0
    seed: 1234
    max_tokens: 3000
    thinking:
      enabled: false                   # Budget/Fast: reasoning disabled (omit 'reasoning')

## Input data
input_file: data/problems_dist20_v1.js # Path to dataset (JSONL-like JS array lines)

## Input filters
filters:
  horn_only: true                      # Keep only horn problems
  skip_rows: 1                         # Skip a header row if present
  limit_rows: null                     # For quick tests; null processes all

## Output data
output_pattern: experiments/runs/${name}/${run}/${provider}/${model}/results.jsonl

## Output configuration
outputs:
  results:
    enabled: true                      # When false, results.jsonl is not written
  provenance:
    enabled: true                      # When false, results.provenance.jsonl is not written
    include_prompt: true               # Include rendered prompt in provenance
    include_raw_response: true         # Include provider raw payload in provenance

## Prompt
prompt:
  template: prompts/exp6_horn_yesno.j2 # Jinja2 template path
  style: horn_if_then                  # One of: horn_if_then | cnf_v1 | cnf_v2
  variables: {}                        # Optional template vars

## Parsing
# Parser maps model text → parsed_answer used in stats:
#   0 = YES/CONTRADICTION, 1 = NO/SATISFIABLE, 2 = UNCLEAR
# For yes_no, we scan the text case-insensitively; first matching token wins.
# If no token matches, parsed_answer=2 and it's counted as UNCLEAR.
# Results also include normalized_text derived from parsed_answer ("yes"/"no").
parse:
  type: yes_no                         # One of: yes_no | contradiction
  yes_tokens: ["yes"]                  # Extra tokens treated as yes (e.g., "yep", "affirmative")
  no_tokens: ["no"]                    # Extra tokens treated as no (e.g., "nope", "negative")

## Concurrency
# Throttling guidance:
# - Effective concurrency per problem = min(workers, number of targets)
# - Set workers >= targets to run all targets in parallel (fastest)
# - Set workers < targets to throttle (reduces 429s/overload spikes, plays nicer with provider limits)
# Examples:
#   workers: 99   # "fast" variant: all targets parallel for each problem
#   workers: 2    # "throttled" variant: at most two requests in flight per problem
concurrency:
  workers: 9                           # Per-problem fan-out workers
  lockstep: true                       # Evaluate the same problem across targets concurrently (lockstep)
  targets_workers: 2                   # Reserved: cap concurrent provider/model groups (not enforced yet)
  rate_limit_per_min: 120              # Reserved: intended per-target limit (not enforced yet)
  retry:
    max_attempts: 3                    # Retries for transient errors (429/overloaded)
    backoff_seconds: [2, 5, 10]        # Per-attempt wait times (seconds); last value reused on further retries

## Execution
resume: true                           # Resume from prior results when re-running

# Optional global thinking defaults (applied to targets without per-target thinking)
thinking:
  enabled: false
  budget_tokens: 2048                  # Default budget for providers that use budgets (Anthropic/Gemini)
  effort: medium                       # Default reasoning effort for OpenAI (low|medium|high)

## CLI tips
# - Limit rows quickly:            --limit 100
# - Dry-run without API calls:     --dry-run
# - Resume interrupted runs:       --resume
# - Restrict providers:            --only anthropic,openai
# - Override models per provider:  --models google:gemini-2.5-pro,openai:gpt-5,
# - Inject run id into ${run}:     --run demo-123
